{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 24: Linear regression and unsupervised learning\n",
    "\n",
    "Plan for today:\n",
    "- Linear regression\n",
    "- Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import YData\n",
    "\n",
    "# YData.download.download_class_code(23)   # get class code    \n",
    "# YData.download.download_class_code(23, TRUE) # get the code with the answers \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using colabs, you should run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install https://github.com/lederman/YData_package/tarball/master\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress ConvergenceWarning - please ignore this code \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = sns.load_dataset(\"penguins\")\n",
    "\n",
    "penguins = penguins.dropna()\n",
    "\n",
    "penguins = penguins.sample(frac = 1)\n",
    "\n",
    "penguins.sort_values(\"body_mass_g\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear regression\n",
    "\n",
    "In regression, we try to predict a quantitative variable y, from a set of features X. \n",
    "\n",
    "Let's explore this by predicting the body mass of penguins (in grams) from other quantitative features of a penguin (e.g., their bill and flipper sizes). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the features and the labels\n",
    "\n",
    "X_penguin_features = penguins[['bill_length_mm', \n",
    "                               'bill_depth_mm',\n",
    "                               'flipper_length_mm']]\n",
    "\n",
    "y_penguin = penguins['body_mass_g']\n",
    "\n",
    "\n",
    "# also save the penguin species to use later\n",
    "y_penguin_species = penguins['species']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use scikit-learn to generate training and test data as we did previously for our KNN classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into a training and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_penguin_features,  \n",
    "                                                    y_penguin, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new linear regression model, fit it to data, and make predictions. The method names are again very similar to what we used for the KNN classifier (i.e., the `fit()` and predict()` methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# create a new linear regression modedl\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model to our training data\n",
    "\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions of the penguins body weight on the test data\n",
    "\n",
    "body_mass_predictions = linear_model.predict(X_test)\n",
    "body_mass_predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assess the accuracy of our predictons using the root mean squared error which is defined as: \n",
    "\n",
    "$$RMSE = \\sqrt{ \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "Here $\\hat{y}$ is the predictions made by our linear model on the test data (i.e., the predicted body weight) and y is the actual body weights for the points in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the RMSE on the test data\n",
    "\n",
    "RMSE = np.sqrt(np.mean((y_test - body_mass_predictions)**2))\n",
    "\n",
    "RMSE   # shows (in grams) how for our predictions of penguin mass is typically off by\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use scikit-learn's `mean_squared_error()` to get the MSE, and we can use the `cross_val_score` to run k-fold cross-validation (again, in a very similar way to what we did for our KNN classifier). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Use scikit-learn's mean_squared_error() function to get the RMSE\n",
    "np.sqrt(mean_squared_error(y_test, body_mass_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(linear_model, \n",
    "                         X_penguin_features,  \n",
    "                         y_penguin, \n",
    "                         cv = 5, \n",
    "                         scoring='neg_mean_squared_error')\n",
    "\n",
    "np.sqrt(np.mean(-1 * scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model equation\n",
    "\n",
    "In linear regression, our predicted $\\hat{y}$ values are given by the equation: $\\hat{y} = b_0 + b_1 x_1 + ... + + b_k x_k$.\n",
    "\n",
    "Let's fill out this equation for prediciting penguin body mass. \n",
    "\n",
    "To do this, let's start by extracting the intercept ($b_0$) and slope coefficients ($b_i's$) from our scikit-learn model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit the linear regression model to our training data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# get the intercept and slope coefficients\n",
    "sklearn_intercept = linear_model.intercept_\n",
    "sklearn_coefficients = linear_model.coef_\n",
    "\n",
    "# print out the coefficient values\n",
    "(sklearn_intercept, sklearn_coefficients)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these coefficient values can you write our the regression equation for predicting penguin body mass? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer\n",
    "\n",
    "$\\hat{y}_{mass} = -6680.13 + 0.5049 \\cdot x_{bill-length} + 21.6384 \\cdot x_{bill-depth} +  52.1411 \\cdot x_{lipper-length}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing our own prediction function\n",
    "\n",
    "Let's also write our own function called `get_predictions(b0_intercept, b_coefficients, X_data)` that takes the coefficient values and X values and returns predicted $\\hat{y}$ values for each X value. In particular, the arguments to the function are:\n",
    "\n",
    "1. `b0_intercept`: The linear regression intercept\n",
    "2. `b_coefficients`: The linear regression slope coefficients\n",
    "3. `X_data`: The X data values \n",
    "\n",
    "The returned value is a numpy ndarray of predictions for each X data point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to get the predictions\n",
    "def get_predictions(b0_intercept, b_coefficients, X_data):\n",
    "    return ...\n",
    "\n",
    "\n",
    "# get the predicted values on the test data\n",
    "predicted_vals = get_predictions(sklearn_intercept, sklearn_coefficients, X_test)\n",
    "\n",
    "\n",
    "# see the it matches the scikit-learn predictions\n",
    "predicted_vals_sklearn = linear_model.predict(X_test)\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on regression coefficients\n",
    "\n",
    "We can also run inference procedures on our regression model using the statsmodel package. In particular, we can run hypothesis tests and create confidence intervals for our regression coefficents. \n",
    "\n",
    "When running a hypothesis test, our hypotheses are:\n",
    "\n",
    "$H_0: \\beta_i = 0$  \n",
    "$H_A: \\beta_i \\ne 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis test on regression coeffients - which coefficients are statistically significantly different from zero? \n",
    "# (and confidence interval)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# add a constant value of 1 to our data\n",
    "X_train_with_constant = sm.add_constant(X_train) \n",
    "\n",
    "# fit the linear regression model using the OLS function\n",
    "sm_linear_model = sm.OLS(y_train, X_train_with_constant).fit()\n",
    "\n",
    "# get information on the regression coefficients found\n",
    "print(sm_linear_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unsupervised learning: clustering\n",
    "\n",
    "We can do k-means clustering in scikit-learn using the `KMeans()` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# fit k-means with 3 clusters \n",
    "\n",
    "kmeans = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which cluster each point belongs to \n",
    "\n",
    "predicted_labels = ...\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a matrix of which penguin types end up in which cluster \n",
    "\n",
    "matrix = pd.DataFrame({'labels': predicted_labels, \n",
    "                       'species': y_penguin_species})\n",
    "\n",
    "\n",
    "ct = pd.crosstab(matrix['labels'], matrix['species'])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# do clustering with feature normalization \n",
    "scaler = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which cluster each (normalized) point belongs to\n",
    "\n",
    "predicted_labels2 = ...\n",
    "\n",
    "predicted_labels2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a matrix of which penguin types end up in which cluster \n",
    "\n",
    "matrix_new = ...\n",
    "\n",
    "ct_new = ...\n",
    "\n",
    "print(ct_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Unsupervised learning: Hierarchical clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "#  Ward's method adds points to a cluster that minimizes the sum of squared differences within all clusters\n",
    "clusters = ...  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a dendrogram\n",
    "dendrogram = hierarchy.dendrogram(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster points into 3 clusters \n",
    "clustering_model = \n",
    "\n",
    "\n",
    "# get the predicted cluster for each point\n",
    "labels = ...\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize how well the clustering matches the penguin species\n",
    "\n",
    "sns.relplot(X_penguin_features, \n",
    "            x='bill_length_mm', \n",
    "            y='flipper_length_mm', \n",
    "            hue=labels, \n",
    "            style = y_penguin_species,\n",
    "            palette=\"Set2\");\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ydata_2025spring_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
