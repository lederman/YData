{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7: Hypothesis tests\n",
    "\n",
    "Welcome to the eighth homework! \n",
    "\n",
    "In this homework you practice running hypothesis tests.\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. \n",
    "\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is due **Sunday April 6th at 11pm.** You can turn in the assignment up to 24 hours late for 90% credit (after that, the homework will only be accepted with a dean's excuse). \n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. The drop-in office hours schedule can be found on Canvas.  You can also post questions or start discussions on Ed Discussion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "In order to complete the homework, it is necessary to download a few files. Please run the code below **only once** to download data needed to complete the homework. To run the code, click in the cell below and press the play button (or press shift-enter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are running this notebook in colabs, please uncomment and run the following two lines\n",
    "# !pip install https://github.com/lederman/YData_package/tarball/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please run this code once to download the files you will need to complete the homework \n",
    "\n",
    "import YData \n",
    "\n",
    "# Downlooad college scorecard data and map files\n",
    "YData.download.download_data(\"college_scorecard_subset_2021_2022.csv\")\n",
    "YData.download.download_data(\"CCBASIC_categories.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Quote and reaction\n",
    "\n",
    "There is no quote and reaction for this week. Please use the extra time to work on your project! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports functions from packages we will use below.\n",
    "# Please run it each time you load the Jupyter notebook\n",
    "\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hypothesis test on a single proportion: Was Paul the Octopus psychic? \n",
    "\n",
    "Paul the Octopus (26 January 2008– 26 October 2010), was a common octopus who was suspected of having psychic abilities. To test Paul’s psychic abilities, workers at the Sea Life Centre in Oberhausen, Germany, assesed whether Paul could predict the winners of the 2010 World Cup soccer games. Before each soccer game, two containers of food (mussels) were lowered into the octopus’ tank. The containers were identical, except for country flags of the opposing teams, one on each container. Whichever container Paul opened was deemed his predicted winner.\n",
    "\n",
    "During the 2010 World Cup, Paul became famous for correctly predicting 11 out of 13 soccer games. We will use hypothesis testing to determine the probability that Paul would get 11 out of 13 correct if he was merely guessing.\n",
    "\n",
    "![Paul](https://c02.purpledshub.com/uploads/sites/41/2018/10/GettyImages-102736984-df583bb.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1 (4 points)**: Please write down the 5 steps for running a hypothesis test. We will use these steps to run an actual hypothesis test in the rest of the problem, but let’s just start by writing down what the steps are. You can look at the lecture slides if you need to, although you should memorize these steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "1. ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2 (5 points)**: Now state the null and alternative hypotheses both using words and as an equation/inequality using the appropriate symbols we discussed in class. I.e., you should have four statements: 2 statements for stating the hypotheses in words, and 2 statments for stating them using symbols. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n",
    "*In words:*\n",
    "\n",
    "\n",
    "\n",
    "*In symbols:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3 (5 points)**: Now please do step 2 of hypothesis testing by computing the statistic of interest and save it in the variable `paul_stat`. In the answer section, please write down the symbol we should use to denote the observed statistic based on the symbols we discussed in class. Also, write down whether you think the value of this observed statistic is likely to be obtained if Paul was guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paul_stat = ...\n",
    "\n",
    "paul_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4 (5 points)**: Let's now to step 3 of hypothesis testing. To start, please write a function `generate_proportion(n, heads_probability)` that simulates a proportion of \"heads\" one might get from flipping *n* coins. Each coin should have a probaility `heads_probability` of getting a \"head\" on each coin flip (assuming each coin flip is independent).\n",
    "\n",
    "Once you have written the `generate_proportion(n, heads_probability)` function, use it to generate one example of a proportion of heads Paul might get if he was merely getting during his World Cup predictions. \n",
    "\n",
    "Hint: Looking at the class 17-18 code might help, but please make sure you are understanding the code you write below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the generate_proportion() function \n",
    "def generate_proportion(n, heads_probability):\n",
    "    ...\n",
    "\n",
    "# use the generate_proportion() function to simulate one example of the proportion of correct predictions Paul might make if he was merely guessing\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5 (5 points)**: Now use for loop and the `generate_proportion()` function to generate a null distribution that would occur if Paul was guessing that has 10,000 simulated proportions. Save the values in this null distribution to a variable called `null_dist`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a null distribution \n",
    "\n",
    "null_dist = []\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6 (5 points)**: Next plot the null distribution as a histogram, set the `bins` argument to 50 so that your histogram has bins. Also add a red circle at the observed statistic value. Based on looking at this plot, what would you estimate the p-value to be? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the null distribution and the observed statistic\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7 (5 points)**: Next do step 4 of hypothesis testing by calculating the p-value and print out the value you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the p-value \n",
    "p_value = ...\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8 (5 points)**: Finally, do step 5 of hypothesis testing and make a judgment call as to whether you believe Paul is psychic based on the\n",
    "p-value and any other information you think is relevant. Make sure to justify your answer to explain Paul’s prediction abilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> **Answer**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis test on mean SAT scores between different types of colleges\n",
    "\n",
    "As you will recall from homework 6, the college scorecard contains data on higher education institutions in the United States. \n",
    "\n",
    "As you will also hopefully recall from creating interactive visualizations of SAT scores on question 1.5 from homework 6, colleges that had the highest SAT scores had Carnegie classifications of \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21). \n",
    "\n",
    "Let's now run a hypothesis test to test whether, on average, students' average SAT scores from \"Doctoral Universities: Very High Research Activity\" is higher than the average SAT scores for students who attend \"Baccalaureate Colleges: Arts & Sciences Focus\"; i.e., is the average SAT score over all scores of these types the same. \n",
    "\n",
    "The college scorecard data is loaded for you in the following cell, and a codebook for a few of the columns is below. \n",
    "\n",
    "\n",
    "#### Codebook\n",
    "\n",
    "1. `UNITID`: Unit ID for institution\n",
    "\n",
    "2. `INSTNM`: Institution name\n",
    "\n",
    "10. `CCBASIC`: Carnegie Classification; e.g., 15 = Doctoral Universities: Very High Research Activity\n",
    "\n",
    "11. `ADM_RATE`: Admission rate\n",
    "\n",
    "12. `SAT_AVG`: Average SAT equivalent score of students admitted\n",
    "\n",
    "18. `TUITFTE`: Net tuition revenue per full-time equivalent student\n",
    "\n",
    "36. `MD_EARN_WNE_MALE0_P10`: Median earnings of non-male students working and not enrolled 10 years after entry\n",
    "\n",
    "37. `MD_EARN_WNE_MALE1_P10`: Median earnings of male students working and not enrolled 10 years after entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard = pd.read_csv(\"college_scorecard_subset_2021_2022.csv\")\n",
    "\n",
    "scorecard.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 (4 points)**: As always, please start your hypothesis test with \"step 1\" by writing down the null and alternative hypotheses using words (i.e., a 1-2 sentence written description) and using the symbols we have discussed in class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "*In words:*\n",
    "\n",
    "\n",
    "\n",
    "*In symbols:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2 (4 points)**: Now let's start on step 2 of hypothesis testing by creating our statistic of interest and visualizing our data. To do this, we need to reduce our data to just the relevant data. Please create a name `scorecard2` which has only data from institutions that are classified as \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21). Also, to make our analyses easier, `scorecard2` should only have two columns which are `CCBASIC` and `SAT_AVG`. \n",
    "\n",
    "Once, you have created this DataFrame, print the first 5 rows, and the number of rows in the DataFrame, to show your work. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3 (3 points)**: Now create a DataFrame called `mean_SAT` which has the mean SAT scores for \"Doctoral Universities: Very High Research Activity\" (`CCBASIC` value of 15) and for \"Baccalaureate Colleges: Arts & Sciences Focus\" (`CCBASIC` value of 21); i.e., there should be two rows correspnding to the two institution types and a single column called `SAT_AVG` which has the average scores for these two institution types averaged over all colleges of a particular type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_SAT = ...\n",
    "\n",
    "mean_SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4 (3 points)**: Now let's actually do step 2 by using the `mean_SAT` DataFrame you created above to create a name `obs_stat` which has the statistic of interest. For our hypothesis test here, our statistic of interest should be $\\bar{x}_{Doc} - \\bar{x}_{Bac}$; where $\\bar{x}_{Doc}$ is the average value of the SAT_AVG scores over all \"Doctoral Universities: Very High Research Activity\" institutions and $\\bar{x}_{Bac}$ is the SAT_AVG scores averaged over all \"Baccalaureate Colleges: Arts & Sciences Focus\" institutions. \n",
    "\n",
    "Print the value of `obs_stat` to show your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_stat = ...\n",
    "obs_stat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5 (4 points)**: Before we go on to step 3 of creating the null distribution, let's visualize the data. \n",
    "\n",
    "Please use seaborn to visualize the data in a way that gives insight into the question of interest. In particular, try to visualize the whole data set in `scorecard2` (rather than just looking at the mean statistics that you calculated above) in a way that gives meaningful insight. In the answer section, report, based on looking at the visualization you created, whether you believe there is a difference in the mean (average) SAT scores between these different type of schools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard3 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6 (4 points)**: Now, let's run step 3 of our hypothesis test by creating a null distribution. \n",
    "\n",
    "To do this, let's first write a function called `mean_diff(scorecard_data)` which takes a \"scorecard\" DataFrame that is the same as the `scorecard2` DataFrame above; i.e., the DataFrame should have a column called `CCBASIC` that has two levels corresponding to Carnegie classification levels 15 and 21, and a column called `SAT_AVG` that has the average SAT scores.\n",
    "\n",
    "From this `scorecard_data` DataFrame, the function should return the difference in means from schools with a `CCBASIC` of Carnegie classification levels 15 and 21.\n",
    "\n",
    "Test that your function works by running it on the `scorecard2` DataFrame and showing that it returns the same observed statistic value that you calculated in quesiton 2.4.\n",
    "\n",
    "\n",
    "Hint: To write this function, simply use the code from questions 2.3 and 2.4 and wrap the code into a function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_diff(scorecard_data):\n",
    "    ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7 (4 points)**: Now let's create one point in our null distribution. \n",
    "\n",
    "To do this, please create a DataFrame called `scorecard_shuff` which is the same as the `scorecard2` DataFrame but the values in the `CCBASIC` column should be shuffled to be in random order. Once you have created this `scorecard_shuff` print the first 5 rows to show that you have done this correctly. \n",
    "\n",
    "Hint: To shuffle the values in the column, passing the `CCBASIC` Series values to the `np.random.permutation()` will be useful. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorecard_shuff = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8 (3 points)**: Now that you have a shuffled data frame, use it with the `mean_diff()` function to generate one statistic consistent with the null distribution. Show that this works by printing the shuffled statistic value below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9 (4 points)**: Now that we can create one statistic consistent with the null hypothesis, we can create a full null distribution by simply repeating this process 10,000 times.\n",
    "\n",
    "Starting with an empty list called `null_dist`, use a for loop to create a null distribution by appending randomly shuffled statistic values onto this list. Print the length of the list at the end of the cell to show the code worked.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_dist = []\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10 (4 points)**: Let's now visualize the null distribution as a histogram. \n",
    "\n",
    "From looking at the null distribution, report in the answer section what you think the p-value will be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(...);\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11 (3 points)**: Now calculate the actual p-value (i.e., the proportion of statistics in the null distribution that are as large or larger than the observed statistic). Print out the p-value below to show your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = ...\n",
    "\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.12 (3 points)**: Based on the p-value you calculated, what can you say about the null hypothesis? What does this lead you to conclude about the mean SAT scores for different types of colleges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reflection (3 points)\n",
    "\n",
    "Please reflect on how the homework went by going to Canvas, going to the Quizzes link, and clicking on reflection on homework 8. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Submission\n",
    "\n",
    "Please submit your assignment as a .pdf on Gradescope. You can access Gradescope through Canvas on the left hand side of the class home page. The problems in each homework assignment are numbered. **NOTE:** When submitting on Gradescope, please select the correct pages of your pdf that correspond to each problem. **Failure to mark pages correctly will result in points being deducted from your homework score.**\n",
    "\n",
    "If you are running Jupyter Notebooks through an Anaconda installation on your own computer, you can produce the .pdf by completing the following steps:  \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook\n",
    "2.  Under \"Download as\", select \"HTML (.html)\"\n",
    "3.  After the .html has downloaded, open it and then select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "4.  From the print window, select the option to save as a .pdf\n",
    "\n",
    "If you are running the assignment in a Google Colabs, you can use the following instructions: \n",
    "1.  Go to \"File\" at the top-left of your Jupyter Notebook and select \"File\" and \"Print\" (note you will not actually be printing)\n",
    "2. From the print window, select the option to save as a .pdf\n",
    "3. Be sure to look over the pdf file to make sure all your code and written work is saved in a clear way."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ydata_2025spring_v1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
